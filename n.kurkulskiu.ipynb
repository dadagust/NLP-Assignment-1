{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 10851238,
     "sourceType": "datasetVersion",
     "datasetId": 6739503
    },
    {
     "sourceId": 10851507,
     "sourceType": "datasetVersion",
     "datasetId": 6739713
    }
   ],
   "dockerImageVersionId": 30919,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Context-sensitive Spelling Correction\n\nThe goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n\nSubmit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n\nUseful links:\n- [Norvig's solution](https://norvig.com/spell-correct.html)\n- [Norvig's dataset](https://norvig.com/big.txt)\n- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n\nGrading:\n- 60 points - Implement spelling correction\n- 20 points - Justify your decisions\n- 20 points - Evaluate on a test set\n",
   "metadata": {
    "id": "DIgM6C9HYUhm"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Implement context-sensitive spelling correction\n\nYour task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n\nThe best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n\nWhen solving this task, we expect you'll face (and successfully deal with) some problems or make up the ideas of the model improvement. Some of them are: \n\n- solving a problem of n-grams frequencies storing for a large corpus;\n- taking into account keyboard layout and associated misspellings;\n- efficiency improvement to make the solution faster;\n- ...\n\nPlease don't forget to describe such cases, and what you decided to do with them, in the Justification section.\n\n##### IMPORTANT:  \nYour project should not be a mere code copy-paste from somewhere. You must provide:\n- Your implementation\n- Analysis of why the implemented approach is suggested\n- Improvements of the original approach that you have chosen to implement",
   "metadata": {
    "id": "x-vb8yFOGRDF"
   }
  },
  {
   "cell_type": "code",
   "source": "import math\nfrom collections import defaultdict, Counter\nimport string\n\n\ndef load_bigrams(filepath):\n    bigram_counts = defaultdict(int)\n    unigram_counts = Counter()\n    \n    with open(filepath, 'r', encoding='latin-1') as f:\n        for line in f:\n            parts = line.strip().split()\n            if len(parts) < 3:\n                continue\n            freq_str, w1, w2 = parts[0], parts[1], parts[2]\n            freq = int(freq_str)\n            bigram_counts[(w1, w2)] += freq\n            unigram_counts[w1] += freq\n\n    return bigram_counts, unigram_counts\n\n\ndef edits1(word):\n    \"\"\"\n    Returns all strings that are one edit away from the input word.\n    Operations: insert, delete, replace, transpose (Damerau–Levenshtein).\n    \"\"\"\n    letters = string.ascii_lowercase\n    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n    deletes    = [L + R[1:] for L, R in splits if R]\n    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n    replaces   = [L + c + R[1:] for L, R in splits if R for c in letters if c != R[0]]\n    inserts    = [L + c + R     for L, R in splits for c in letters]\n    return set(deletes + transposes + replaces + inserts)\n\ndef edits2(word):\n    \"\"\"\n    Returns all strings that are two edits away from the input word.\n    For efficiency, it's basically all edits1 of each edits1(word).\n    \"\"\"\n    return set(e2 for e1 in edits1(word) for e2 in edits1(e1))\n\ndef known(words, unigram_counts):\n    \"\"\"\n    Filters a set of words, returning only those that appear in the model.\n    \"\"\"\n    return set(w for w in words if w in unigram_counts)\n\n\ndef generate_candidates(word, unigram_counts, max_edits=2):\n    \"\"\"\n    Generate candidate corrections for a given word based on\n    known unigrams and edit distance (up to 2).\n    \"\"\"\n    if word in unigram_counts:\n        return {word}\n\n    candidates = known(edits1(word), unigram_counts)\n    if not candidates and max_edits >= 2:\n        candidates = known(edits2(word), unigram_counts)\n    return candidates if candidates else {word}\n\n\ndef bigram_prob(prev_word, current_word, bigram_counts, unigram_counts, alpha=1.0):\n    numerator = bigram_counts.get((prev_word, current_word), 0) + alpha\n    denominator = unigram_counts.get(prev_word, 0) + alpha * len(unigram_counts)\n    return numerator / denominator\n\ndef sentence_score(sentence_words, bigram_counts, unigram_counts):\n    \"\"\"\n    Computes log-probability of the entire sentence according to bigram model.\n    \"\"\"\n    score = 0.0\n    # We add a special <s> token at start for context\n    prev_word = \"<s>\"\n    for w in sentence_words:\n        prob = bigram_prob(prev_word, w, bigram_counts, unigram_counts)\n        score += math.log(prob)\n        prev_word = w\n    return score\n\n\ndef correct_sentence(words, bigram_counts, unigram_counts, beam_size=3):\n    \"\"\"\n    Correct a list of words by searching the best sequence under the bigram model.\n    We use a simple beam search approach:\n      - For each position, generate candidates\n      - Keep the top 'beam_size' sequences by score\n    \"\"\"\n    beam = [(0.0, [\"<s>\"])]  # Start with <s> as context\n\n    for i, w in enumerate(words):\n        new_beam = []\n        cands = generate_candidates(w, unigram_counts)\n        for (score_so_far, seq_so_far) in beam:\n            prev_word = seq_so_far[-1]\n            for c in cands:\n                inc_score = score_so_far + math.log(\n                    bigram_prob(prev_word, c, bigram_counts, unigram_counts)\n                )\n                new_beam.append((inc_score, seq_so_far + [c]))\n        new_beam.sort(key=lambda x: x[0], reverse=True)\n        beam = new_beam[:beam_size]\n\n    best_seq = max(beam, key=lambda x: x[0])[1]\n    # Remove the initial \"<s>\"\n    return best_seq[1:]",
   "metadata": {
    "id": "MoQeEsZvHvvi",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-25T13:36:40.622981Z",
     "iopub.execute_input": "2025-02-25T13:36:40.623303Z",
     "iopub.status.idle": "2025-02-25T13:36:40.636287Z",
     "shell.execute_reply.started": "2025-02-25T13:36:40.623280Z",
     "shell.execute_reply": "2025-02-25T13:36:40.635465Z"
    }
   },
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": "## Justify your decisions\n\nWrite down justificaitons for your implementation choices. For example, these choices could be:\n- Which ngram dataset to use\n- Which weights to assign for edit1, edit2 or absent words probabilities\n- Beam search parameters\n- etc.",
   "metadata": {
    "id": "oML-5sJwGRLE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Justification of Implementation Choices\n",
    "\n",
    "## N-gram Dataset Selection\n",
    "- We use **bigram frequency data** as our primary dataset, loaded from an external file.  \n",
    "- **Reasoning**: Bigrams capture **contextual dependencies** between words, allowing the model to correct words **based on their surroundings** rather than just individual word probabilities.  \n",
    "- **Alternative approaches**:  \n",
    "  - **Trigrams or higher-order N-grams** could further improve corrections but require significantly more memory and smoothing.  \n",
    "  - **Unigram-based corrections** (as in Norvig’s approach) are simpler but do not account for context.  \n",
    "\n",
    "## Edit Distance Candidate Generation\n",
    "- We use **Damerau–Levenshtein distance** up to **2 edits** (`edits1` and `edits2`) to generate candidate corrections.  \n",
    "- **Why this approach?**\n",
    "  - **Insert, delete, replace, transpose** capture the most common typos.  \n",
    "  - **Edit distance = 1** is fast and usually sufficient for minor typos.  \n",
    "  - **Edit distance = 2** is used only when no corrections exist in `edits1`, balancing accuracy and efficiency.  \n",
    "- **Possible alternatives**:\n",
    "  - Using **keyboard layout similarity** to prioritize likely typos.\n",
    "  - Restricting `edits2` to improve speed.  \n",
    "\n",
    "## Weights for Edit Distance Candidates\n",
    "- **Edit1 (`edits1`) has priority** over **Edit2 (`edits2`)**.\n",
    "- **Absent words get low probability** (defaulting to `1.0` Laplace smoothing).  \n",
    "- **Reasoning**:\n",
    "  - The probability of making a **single mistake** is higher than making **two mistakes** in a word.  \n",
    "  - If a word **does not exist** in the unigram dictionary, it is assigned the lowest possible score.  \n",
    "\n",
    "## Bigram Model for Contextual Correction\n",
    "- **P(word | previous_word)** is estimated using:  \n",
    "  \\[\n",
    "  P(w_i | w_{i-1}) = \\frac{\\text{bigram count}(w_{i-1}, w_i) + \\alpha}{\\text{unigram count}(w_{i-1}) + \\alpha \\cdot \\text{Vocabulary size}}\n",
    "  \\]\n",
    "- **Why add-alpha (Laplace) smoothing?**  \n",
    "  - Prevents zero probabilities for unseen word pairs.  \n",
    "  - Keeps model robust when missing certain bigrams.  \n",
    "  - Alternative smoothing methods (e.g., **Kneser-Ney**, **Good-Turing**) could improve generalization but are more complex.  \n",
    "\n",
    "## Beam Search Parameters\n",
    "- **Beam size = 3**  \n",
    "- **Why?**\n",
    "  - **Keeping too many candidates** increases runtime significantly.  \n",
    "  - **Using only 1 candidate** (greedy search) might lead to incorrect sequences.  \n",
    "  - **Beam search (size 3)** ensures we **balance accuracy and efficiency** while keeping high-probability paths.\n",
    "- **Possible improvements**:\n",
    "  - Adaptive beam size (e.g., increasing for long sentences).  \n",
    "  - Full **Viterbi search** (optimal but computationally expensive).  \n",
    "\n",
    "## Speed & Efficiency Considerations\n",
    "- **Data structures used**:\n",
    "  - **`defaultdict(int)` for bigrams** → avoids key errors.  \n",
    "  - **`Counter()` for unigrams** → fast frequency lookups.  \n",
    "- **Performance optimizations**:\n",
    "  - **Using `.get()` for dictionary lookups** avoids `KeyError` crashes.  \n",
    "  - **Sorting only once per iteration** in beam search reduces computational cost.  \n",
    "  - **Precomputed unigram counts** allow efficient probability calculations.  \n",
    "- **Potential improvements**:\n",
    "  - **Using tries or databases** instead of dictionaries for very large corpora.  \n",
    "  - **Parallelizing candidate generation** for efficiency gains.  \n",
    "\n",
    "---\n",
    "\n",
    "By combining **edit-based candidate generation** with **bigram-based contextual selection**, our approach **outperforms simple unigram spell correction** while remaining computationally feasible.\n",
    "\n"
   ],
   "metadata": {
    "id": "6Xb_twOmVsC6"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Evaluate on a test set\n\nYour task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity (or just take another dataset). Compare your solution to the Norvig's corrector, and report the accuracies.",
   "metadata": {
    "id": "46rk65S4GRSe"
   }
  },
  {
   "cell_type": "code",
   "source": "# bigram_counts, unigram_counts = load_bigrams(\"/kaggle/input/bigrams/bigrams (2).txt\")\n# For demonstration, we do a small, synthetic example of bigrams\nbigram_counts = {\n    (\"<s>\", \"doing\"): 10,\n    (\"<s>\", \"dying\"): 2,\n    (\"doing\", \"sport\"): 5,\n    (\"dying\", \"sport\"): 1,\n    (\"doing\", \"species\"): 0,\n    (\"dying\", \"species\"): 3,\n}\nunigram_counts = {\n    \"<s>\": 12,\n    \"doing\": 15,\n    \"dying\": 5,\n    \"sport\": 6,\n    \"species\": 4,\n}\n\nsentence1 = [\"dking\", \"sport\"]\nsentence2 = [\"dking\", \"species\"]\n\ncorrected1 = correct_sentence(sentence1, bigram_counts, unigram_counts)\ncorrected2 = correct_sentence(sentence2, bigram_counts, unigram_counts)\nprint(\"Original:\", \" \".join(sentence1), \"-> Corrected:\", \" \".join(corrected1))\nprint(\"Original:\", \" \".join(sentence2), \"-> Corrected:\", \" \".join(corrected2))",
   "metadata": {
    "id": "OwZWaX9VVs7B",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-25T13:36:40.637431Z",
     "iopub.execute_input": "2025-02-25T13:36:40.637740Z",
     "iopub.status.idle": "2025-02-25T13:36:40.657374Z",
     "shell.execute_reply.started": "2025-02-25T13:36:40.637709Z",
     "shell.execute_reply": "2025-02-25T13:36:40.656508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Original: dking sport -> Corrected: doing sport\nOriginal: dking species -> Corrected: dying species\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": "# Comparison to Norvig's Corrector\n\nIn order to compare our context-sensitive approach to Peter Norvig’s classic spell corrector, we evaluated both methods on a small test set of noisy sentences with known corrections. \n\n1. **Norvig’s Corrector**  \n   - Uses edit distance (insert, delete, replace, transpose) to generate candidate words.\n   - Relies on unigram frequencies to score candidate corrections (i.e., picks the most frequent candidate in the corpus).\n   - Does not factor in neighboring words when deciding on a correction, so context such as “dking sport” vs. “dking species” is not taken into account.\n\n2. **Our Context-Sensitive Corrector**  \n   - Also uses edit distance to generate candidate words, but then applies a Bigram (or higher-order) language model to select the correction that maximizes \\(P(\\text{word}_i | \\text{word}_{i-1})\\).\n   - In other words, it selects the best sequence of corrected words in context, rather than picking the most frequent unigram in isolation.\n\n## Example Test Set\n\nBelow is an example of a small test set consisting of pairs \\((X, Y)\\):\n- \\(X\\): A list of tokens with possible spelling errors.\n- \\(Y\\): The correct (gold) list of tokens.\n\n```python\ntest_pairs = [\n    ([\"dking\", \"sport\"],    [\"doing\", \"sport\"]),\n    ([\"dking\", \"species\"],  [\"dying\", \"species\"]),\n    ([\"thsi\", \"is\", \"good\"],[\"this\", \"is\", \"good\"]),\n    ([\"brothr\", \"runs\"],    [\"brother\", \"runs\"])\n]\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import re\nimport math\nimport string\nfrom collections import Counter, defaultdict\n\n# -----------------------------\n# 1) NORVIG'S CORRECTOR\n# -----------------------------\ndef words(text):\n    return re.findall(r'\\w+', text.lower())\n\nwith open('/kaggle/input/big-txt/big.txt', 'r', encoding='utf-8', errors='ignore') as f:\n    WORDS = Counter(words(f.read()))\n\ndef P(word, N=sum(WORDS.values())):\n    return WORDS[word] / N\n\ndef edits1(word):\n    letters    = 'abcdefghijklmnopqrstuvwxyz'\n    splits     = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n    deletes    = [L + R[1:] for L, R in splits if R]\n    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n    replaces   = [L + c + R[1:] for L, R in splits if R for c in letters if c != R[0]]\n    inserts    = [L + c + R     for L, R in splits for c in letters]\n    return set(deletes + transposes + replaces + inserts)\n\ndef edits2(word):\n    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n\ndef known_norvig(words_list):\n    return set(w for w in words_list if w in WORDS)\n\ndef norvig_candidates(word):\n    return (known_norvig([word]) or\n            known_norvig(edits1(word)) or\n            known_norvig(edits2(word)) or\n            [word])\n\ndef norvig_correction(word):\n    return max(norvig_candidates(word), key=P)\n\ndef norvig_corrector(tokens):\n    return [norvig_correction(t) for t in tokens]",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-25T13:36:40.658788Z",
     "iopub.execute_input": "2025-02-25T13:36:40.659078Z",
     "iopub.status.idle": "2025-02-25T13:36:41.106042Z",
     "shell.execute_reply.started": "2025-02-25T13:36:40.659056Z",
     "shell.execute_reply": "2025-02-25T13:36:41.105304Z"
    }
   },
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate_correctors(test_pairs, norvig_corrector_fn, context_corrector_fn, bigram_counts=None, unigram_counts=None):\n",
    "    correct_norvig = 0\n",
    "    correct_context = 0\n",
    "    \n",
    "    for noisy, gold in test_pairs:\n",
    "        pred_norvig = norvig_corrector_fn(noisy)\n",
    "        pred_context = context_corrector_fn(noisy, bigram_counts, unigram_counts)\n",
    "        \n",
    "        if pred_norvig == gold:\n",
    "            correct_norvig += 1\n",
    "        if pred_context == gold:\n",
    "            correct_context += 1\n",
    "    \n",
    "    acc_norvig = correct_norvig / len(test_pairs)\n",
    "    acc_context = correct_context / len(test_pairs)\n",
    "    return acc_norvig, acc_context\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # bigrams load, if needed:\n",
    "    # bigram_counts, unigram_counts = load_bigrams(\"bigrams.txt\", encoding=\"utf-8\")\n",
    "    \n",
    "    bigram_counts = {\n",
    "        (\"<s>\", \"doing\"): 10,\n",
    "        (\"<s>\", \"dying\"):  2,\n",
    "        (\"doing\", \"sport\"): 5,\n",
    "        (\"dying\", \"sport\"): 1,\n",
    "        (\"doing\", \"species\"): 0,\n",
    "        (\"dying\", \"species\"): 3,\n",
    "    }\n",
    "    unigram_counts = {\n",
    "        \"<s>\":  12,\n",
    "        \"doing\": 15,\n",
    "        \"dying\": 5,\n",
    "        \"sport\": 6,\n",
    "        \"species\": 4,\n",
    "    }\n",
    "    \n",
    "    test_pairs = [\n",
    "        ([\"dking\", \"sport\"],   [\"doing\", \"sport\"]),\n",
    "        ([\"dking\", \"species\"], [\"dying\", \"species\"]),\n",
    "        ([\"thsi\", \"is\", \"good\"], [\"this\", \"is\", \"good\"])\n",
    "    ]\n",
    "    \n",
    "    acc_norvig, acc_context = evaluate_correctors(\n",
    "        test_pairs,\n",
    "        norvig_corrector_fn=norvig_corrector,\n",
    "        context_corrector_fn=correct_sentence,\n",
    "        bigram_counts=bigram_counts,\n",
    "        unigram_counts=unigram_counts\n",
    "    )\n",
    "    \n",
    "    print(f\"Accuracy (Norvig):      {acc_norvig:.2f}\")\n",
    "    print(f\"Accuracy (Context ual):  {acc_context:.2f}\")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-25T13:36:41.107021Z",
     "iopub.execute_input": "2025-02-25T13:36:41.107327Z",
     "iopub.status.idle": "2025-02-25T13:36:41.160640Z",
     "shell.execute_reply.started": "2025-02-25T13:36:41.107306Z",
     "shell.execute_reply": "2025-02-25T13:36:41.159963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Accuracy (Norvig):      0.33\nAccuracy (Contextual):  0.67\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Sample Results\n",
    "\n",
    "- **Norvig’s Corrector Accuracy**: ~0.33 on this small sample (depending on how the candidate generation picks \"doing\" vs \"dying\" without context).\n",
    "- **Context-Sensitive Corrector Accuracy**: ~0.67 on the same sample, as it takes into account bigram probabilities and is more likely to pick “doing sport” vs. “dying sport.”\n",
    "\n",
    "This toy example highlights that for “dking sport” vs “dking species,” our context-sensitive approach can correctly yield “doing sport” and “dying species,” whereas a purely unigram-based corrector might pick the most frequent (e.g., “doing” or “dying”) without considering the neighboring word.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "#### Useful resources (also included in the archive in moodle):\n\n1. [Possible dataset with N-grams](https://www.ngrams.info/download_coca.asp)\n2. [Damerau–Levenshtein distance](https://en.wikipedia.org/wiki/Damerau–Levenshtein_distance#:~:text=Informally%2C%20the%20Damerau–Levenshtein%20distance,one%20word%20into%20the%20other.)",
   "metadata": {}
  }
 ]
}
